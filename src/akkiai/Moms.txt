1. Create branches main and <sub-branches> 
2. Passing kickoff id for human input for real time conversation (API, )
3. Supabase integrate do not create local copy of supabase. Create project id and url and iteract with the database 
4. Create database with supabase with a kickoff id.
5. job_id 
6. 2 tables table 1 ID auto generated by supabase kickoff id from crew  3rd would be status of that job, created date and updated date.
7. Status of the job 
8. Table 2 "task table" for every kickoff id we have a comb (task id, task1, task1) input output of each task.
9. Inputs fields are for human inputs only. That will be used for 
10. Keep status of task. 

kickoff---5 tasks---(combination of kickoff, task_id, input, output)

Python supabase integration Supabase project.
Each project URL and API Key.


Supabase Integration with EC2 Instance

1. URL https://rqgwnmknmivdgfzbclzh.supabase.co
2. anon : eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InJxZ3dubWtubWl2ZGdmemJjbHpoIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MzM0MTk3NDksImV4cCI6MjA0ODk5NTc0OX0.vKTEKLPZcGrdlMgkS55a4cSnDxx8bdSupi0VkSkQRD4
3. service role: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InJxZ3dubWtubWl2ZGdmemJjbHpoIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTczMzQxOTc0OSwiZXhwIjoyMDQ4OTk1NzQ5fQ.3S82fepFGeelGt_oTwYAu8IONsjuCf-Zft78UyakgEo 

MoM (6 Dec 24)

1. Read docs, can we pass kickoff_id to run? associating it with the crew and i/o
2. Intermediate tasks output
3. Parallel crew execution 
4. Can we get crew enterprise features in our system? 
5. Get kickoff_id and fields that are available in crew ai enterprise.
 


 How did i extract task oputputs real time?
 https://github.com/crewAIInc/crewAI/issues/496 

MoM 7th Dec 

1. Try it out for parallel execution of crews. Kickoff ids should be unique as well.
2. Access the crew ai id that is been created, send it as an output as well. Access variable from the Class.
3. Inputs of each task should be extracted. 

MoM 10th Dec 

1. Task output fields have "name_kickoff_id". For every run of crew the combination of taskname and crew kickoff id 
would be unique and readable. 
2. soln id and associated task id 
3. User enters data, PUT into table messages then doing kickoff of the job then kickoff_id into table.
4. The problem is that we are calling more APIs, more chances of errors. Loose track of APIs
5. What if we use message then it gets inserted then i call the kickoff id and update the table.
6. Kickoff updateion later makes failure 
7. Push the job id to build failprroof mechasnism 
8. Job table, solution table with soln _id with task_id 
9. Using job_id and task_name to create a task 
10. Task name againts soln task table 
11. Task id dont have random number, go with task table, 1 field job_id and task_name. job_id with kickoff_id.
12. Parallel  


1. Outputs are coming same, kickoff_id are coming different? 
2. Max parallel execution how to run?
3. How to get api calls for this and the integrate , get url of solution and plug it with webhook. 
4. Task outputs how that will be accessed async updatew ho jaye? Webhook solution 

MoM 13th 

1. uNDERSTAND flow of the await and threaded 
2. Pass the kickoff id as response to the api call (Outputs)
3. Task outputs after the database push should call an external API immediately. 
4. POST call (kickoff_id, task_name, output) to the existing system. 
5. Each task output make post call for that task.
6. Push it to activepieces webhook. (Read more about) 
7. create Status/kickoff_id/task_name end points should show response of status and final outputs. (Will act as a backup)
8. 3 major things to work on.